# coding=utf8

import re
import torch
import models
import tensorflow as tf

MAX_LEN = 64
TRAIN_BATCH = 32
TEST_BATCH = 16
N_LAYER = 1
EMBED_DIM = 32
HIDDEN_DIM = 256
EPOCHS = 3
learning_rate = 0.01
PATIENCE = 2
NUM_CLASSES = 7


stopwords = ['অবশ্য', 'অনেক', 'অনেকে', 'অনেকেই', 'অন্তত', 'অথবা', 'অথচ', 'অর্থাত', 'অন্য', 'আজ', 'আছে', 'আপনার', 'আপনি', 'আবার', 'আমরা', 'আমাকে', 'আমাদের', 'আমার', 'আমি', 'আরও', 'আর', 'আগে', 'আগেই', 'আই', 'অতএব', 'আগামী', 'অবধি', 'অনুযায়ী', 'আদ্যভাগে', 'এই', 'একই', 'একে', 'একটি', 'এখন', 'এখনও', 'এখানে', 'এখানেই', 'এটি', 'এটা', 'এটাই', 'এতটাই', 'এবং', 'একবার', 'এবার', 'এদের', 'এঁদের', 'এমন', 'এমনকী', 'এল', 'এর', 'এরা', 'এঁরা', 'এস', 'এত', 'এতে', 'এসে', 'একে', 'এ', 'ঐ', ' ই', 'ইহা', 'ইত্যাদি', 'উনি', 'উপর', 'উপরে', 'উচিত', 'ও', 'ওই', 'ওর', 'ওরা', 'ওঁর', 'ওঁরা', 'ওকে', 'ওদের', 'ওঁদের', 'ওখানে', 'কত', 'কবে', 'করতে', 'কয়েক', 'কয়েকটি', 'করবে', 'করলেন', 'করার', 'কারও', 'করা', 'করি', 'করিয়ে', 'করার', 'করাই', 'করলে', 'করলেন', 'করিতে', 'করিয়া', 'করেছিলেন', 'করছে', 'করছেন', 'করেছেন', 'করেছে', 'করেন', 'করবেন', 'করায়', 'করে', 'করেই', 'কাছ', 'কাছে', 'কাজে', 'কারণ', 'কিছু', 'কিছুই', 'কিন্তু', 'কিংবা', 'কি', 'কী', 'কেউ', 'কেউই', 'কাউকে', 'কেন', 'কে', 'কোনও', 'কোনো', 'কোন', 'কখনও', 'ক্ষেত্রে', 'খুব,\t\n', 'গুলি', 'গিয়ে', 'গিয়েছে', 'গেছে', 'গেল', 'গেলে', 'গোটা', 'চলে', 'ছাড়া', 'ছাড়াও', 'ছিলেন', 'ছিল', 'জন্য', 'জানা', 'ঠিক', 'তিনি', 'তিনঐ', 'তিনিও', 'তখন', 'তবে', 'তবু', 'তাঁদের', 'তাঁহারা', 'তাঁরা', 'তাঁর', 'তাঁকে', 'তাই', 'তেমন', 'তাকে', 'তাহা', 'তাহাতে', 'তাহার', 'তাদের', 'তারপর', 'তারা', 'তারৈ', 'তার', 'তাহলে', 'তিনি', 'তা', 'তাও', 'তাতে', 'তো', 'তত', 'তুমি', 'তোমার', 'তথা', 'থাকে', 'থাকা', 'থাকায়', 'থেকে', 'থেকেও', 'থাকবে', 'থাকেন', 'থাকবেন', 'থেকেই', 'দিকে', 'দিতে', 'দিয়ে', 'দিয়েছে', 'দিয়েছেন', 'দিলেন', 'দু', 'দুটি', 'দুটো', 'দেয়', 'দেওয়া', 'দেওয়ার', 'দেখা', 'দেখে', 'দেখতে', 'দ্বারা', 'ধরে', 'ধরা', 'নয়', 'নানা', 'না', 'নাকি', 'নাগাদ', 'নিতে', 'নিজে', 'নিজেই', 'নিজের', 'নিজেদের', 'নিয়ে', 'নেওয়া', 'নেওয়ার', 'নেই', 'নাই', 'পক্ষে', 'পর্যন্ত', 'পাওয়া', 'পারেন', 'পারি', 'পারে', 'পরে', 'পরেই', 'পরেও', 'পর', 'পেয়ে', 'প্রতি', 'প্রভৃতি', 'প্রায়', 'ফের', 'ফলে', 'ফিরে', 'ব্যবহার', 'বলতে', 'বললেন', 'বলেছেন', 'বলল', 'বলা', 'বলেন', 'বলে', 'বহু', 'বসে', 'বার', 'বা', 'বিনা', 'বরং', 'বদলে', 'বাদে', 'বার', 'বিশেষ', 'বিভিন্ন', 'বিষয়টি', 'ব্যবহার', 'ব্যাপারে', 'ভাবে', 'ভাবেই', 'মধ্যে', 'মধ্যেই', 'মধ্যেও', 'মধ্যভাগে', 'মাধ্যমে', 'মাত্র', 'মতো', 'মতোই', 'মোটেই', 'যখন', 'যদি', 'যদিও', 'যাবে', 'যায়', 'যাকে', 'যাওয়া', 'যাওয়ার', 'যত', 'যতটা', 'যা', 'যার', 'যারা', 'যাঁর', 'যাঁরা', 'যাদের', 'যান', 'যাচ্ছে', 'যেতে', 'যাতে', 'যেন', 'যেমন', 'যেখানে', 'যিনি', 'যে', 'রেখে', 'রাখা', 'রয়েছে', 'রকম', 'শুধু', 'সঙ্গে', 'সঙ্গেও', 'সমস্ত', 'সব', 'সবার', 'সহ', 'সুতরাং', 'সহিত', 'সেই', 'সেটা', 'সেটি', 'সেটাই', 'সেটাও', 'সম্প্রতি', 'সেখান', 'সেখানে', 'সে', 'স্পষ্ট', 'স্বয়ং', 'হইতে', 'হইবে', 'হৈলে', 'হইয়া', 'হচ্ছে', 'হত', 'হতে', 'হতেই', 'হবে', 'হবেন', 'হয়েছিল', 'হয়েছে', 'হয়েছেন', 'হয়ে', 'হয়নি', 'হয়', 'হয়েই', 'হয়তো', 'হল', 'হলে', 'হলেই', 'হলেও', 'হলো', 'হিসাবে', 'হওয়া', 'হওয়ার', 'হওয়ায়', 'হন', 'হোক', 'জন', 'জনকে', 'জনের', 'জানতে', 'জানায়', 'জানিয়ে', 'জানানো', 'জানিয়েছে', 'জন্য', 'জন্যওজে', 'জে', 'বেশ', 'দেন', 'তুলে', 'ছিলেন', 'চান', 'চায়', 'চেয়ে', 'মোট', 'যথেষ্ট', 'টি']
text = '  অধ্যায়    প্রিয়    পরীক্ষার্থী    তথ্য    যোগাযোগ    প্রযুক্তি    বিষয়ের    সৃজনশীল    নমুনা    প্রশ্নোত্তর    করিম    সাহেব    একজন    ব্যবসায়ী    ছোট    ভাই    মাসুদকে    অফিসের    কম্পিউটারগুলো    পরস্পরের    সংযোগের    কেব্ল    অর্থসাশ্রয়ী    সহজে    স্থাপনযোগ্য    ছোট    ভাই    মাসুদের    অফিসে    দেখলেন    অফিসে    সেদিন    কম্পিউটার    কাজ    অনুসন্ধানে    কম্পিউটারের    সংযোগ    কেব্ল    নষ্ট    পরের    দিন    ভাইয়ের    অফিসে    দেখলেন    অফিসের    কম্পিউটার    কেন্দ্রীয়    ডিভাইসের    সংযুক্ত    মডেম    ট্রান্সমিশন    মোডে    উভয়    ডেটা    আদান    প্রদান    ব্যাখ্যা    করো    করিম    সাহেবের    অফিসে    ব্যবহূত    কেব্লটি    ধরনের    ব্যাখ্যা    করো    নেটওয়ার্ক    সংযোগের    উদ্দীপকে    উল্লিখিত    ব্যবস্থাদ্বয়ের    কোনটি    উত্তম    বিশ্লেষণপূর্বক    মতামত    দাও    উত্তর    কমডেম    সংক্ষিপ্ত    রূপ    মডেম    ইলেকট্রনিক    ডিভাইস    অ্যানালগ    সংকেতকে    ডিজিটাল    ডিজিটাল    সংকেতকে    অ্যানালগ    সংকেতে    রূপান্তর    উত্তর    খফুল    ডুপ্লেক্স    মোডে    উভয়    ডেটা    আদান    প্রদান    ডেটা    ট্রান্সমিশন    মোডে    ডেটা    উত্স    গন্তব্যের    গন্তব্য    উেসর    প্রবাহিত    ফুল    ডুপ্লেক্স    মোড    অর্থাত্    পদ্ধতিতে    ডেটাপ্রবাহ    যুগোপযোগীভাবে    সম্পন্ন    মোবাইল    ফোন    টেলিফোন    উত্তর    গকরিম    সাহেবের    অফিসের    কেব্লটি    টুইস্টেড    পেয়ার    কেব্ল    পরিবাহী    তারকে    পরস্পর    পেঁচিয়ে    টুইস্টেড    পেয়ার    কেব্ল    তৈরি    প্যাঁচানো    দুটিকে    পৃথক    রাখার    মাঝে    অপরিবাহী    পদার্থ    অন্যান্য    কেবলের    তুলনায়    টুইস্টেড    পেয়ার    কেব্ল    অর্থসাশ্রয়ী    সহজে    স্থাপনযোগ্য    উদ্দীপকে    করিম    সাহেবের    অফিসের    কম্পিউটার    পরস্পরের    সংযোগের    কেব্ল    ব্যবহূত    অর্থসাশ্রয়ী    সহজে    স্থাপনযোগ্য    করিম    সাহেবের    অফিসের    কেব্লটি    টুইস্টেড    পেয়ার    কেব্ল    উত্তর    ঘনেটওয়ার্ক    সংযোগের    উদ্দীপকে    উল্লিখিত    ব্যবস্থা    রিং    টপোলজি    স্টার    টপোলজি    কম্পিউটার    নেটওয়ার্কে    কম্পিউটারের    অপর    কম্পিউটারের    সংযোগব্যবস্থাকেই    টপোলজি    সংগঠনে    কম্পিউটারগুলো    পরস্পর    যুক্ত    বৃত্তাকার    নেটওয়ার্ক    গড়ে    তোলে    রিং    টপোলজি    টপোলজিতে    কম্পিউটারের    সংযোগ    নষ্ট    কম্পিউটারেই    কাজ    সংগঠনে    কেন্দ্রীয়    ডিভাইসের    অন্যান্য    কম্পিউটার    সংযুক্ত    স্টার    টপোলজি    উদ্দীপকে    মাসুদ    সাহেবের    অফিসে    সেদিন    কম্পিউটারই    কাজ    করেনি    কম্পিউটারের    সংযোগ    নষ্ট    রিং    টপোলজি    অন্যদিকে    ভাই    করিম    সাহেবের    অফিসের    কম্পিউটার    কেন্দ্রীয়    ডিভাইসের    সংযুক্ত    স্টার    টপোলজি    উদ্দীপকের    রিং    স্টার    টপোলজির    স্টার    টপোলজি    উত্তম    রিং    টপোলজিতে    কম্পিউটার    কারণে    নষ্ট    অপসারণ    পুরো    নেটওয়ার্ক    অচল    পড়ে    স্টার    টপোলজিতে    কখনোই    মাস্টার    ট্রেইনারপ্রভাষক    রাউজান    কলেজ    চট্টগ্রাম  '


def clean_data_text(text):
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    text = re.sub('\s+', ' ', text)
    text = re.sub('^\s+|\s+?$', '', text)  
    return text


label = {'economy': 0,
            'education': 1,
            'entertainment': 2,
            'international': 3,
            'sports': 4,
            'state': 5,
            'technology': 6}
new = torch.load("./best_model_at_epoch_2_fold_4.pth.tar", map_location=torch.device("cpu"))['state_dict']

clean_text = clean_data_text(text)
stop = set(stopwords)
clean_text = ' '.join([word for word in clean_text.split() if word not in stop])

tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts([clean_text])
new_text = tokenizer.texts_to_sequences([clean_text])

new_text = tf.keras.preprocessing.sequence.pad_sequences(
    new_text, maxlen=MAX_LEN
)

sent_loader = torch.utils.data.DataLoader(
    new_text, batch_size=1
)
model = models.MultiClassModel(
        input_dim=464008,
        n_layer=N_LAYER,
        embedding_dim=EMBED_DIM,
        hidden_dim=HIDDEN_DIM,
        output_dim=NUM_CLASSES
)
model = model.to("cpu")
model.load_state_dict(new)
model.eval().cpu()
with torch.no_grad():
    for x in sent_loader:
        x = x.to("cpu")
        output = model(x)
        print(torch.argmax(output, keepdim=True))